{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Madden Ultimate Team (MUT) Auction House Analyzer\n",
    "#### Matthew Johnson, March 21, 2018\n",
    "\n",
    "A set in madden is where you buy n specific cards to complete the set and recieve a more valuable player in return.\n",
    "\n",
    "Currently:\n",
    "- Currently running two parallel arrays of set players and their ids\n",
    "- Keep track of target player and target_id \n",
    "- Use selenium to open webdriver Firefox\n",
    "- Manually log into 'Muthead' (Must be logged in to refresh auction prices)\n",
    "- Selenium refreshes all of the auction prices of relevant players page by page\n",
    "- Use beautifulsoup to scrape from three tables: Current Auctions, Completed Sales, and 'Stats for Nerds'\n",
    "- Using the minimum BuyNow price for each player, the price to complete the set is calculated\n",
    "- Using this, an average of last X sales of player and taking into account the 10% tax fee on the Auction House a conditional is triggered to pursue the set based on expected profit\n",
    "\n",
    "Current Pitfalls:\n",
    "- Need to manually login\n",
    "- Poor flow\n",
    "- Likely needs proper use of .sleep() \n",
    "\n",
    "Planned:\n",
    "- store data, pickle?\n",
    "- to also use for non-set (rare) players\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RUN THIS\n",
    "\n",
    "browser = webdriver.Firefox()\n",
    "\n",
    "URL = 'https://www.muthead.com/twitch-login?returnUrl=%2f'\n",
    "\n",
    "browser.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#manually log in\n",
    "\n",
    "# username = 'XXXXXXXX'\n",
    "# password = 'XXXXXXXX'\n",
    "\n",
    "# data frame to store scraped data\n",
    "data = pd.DataFrame(columns=['Name', 'Min Price', 'Average', 'Date'], index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods<br>\n",
    "#### All take in a beautiful soup object:\n",
    "- retrieve_prices(soup): returns a dataframe of current auctions\n",
    "- retrieve_stats(soup): returns a dataframe of stats for the last 100 sales such as quartile prices, min, avg, etc.\n",
    "- retrieve_sales(soup): returns dataframe of last 10 completed sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_prices(soup):    # method that returns a dataframe of current auctions\n",
    "    \n",
    "    print (soup.title.text) # print player page title\n",
    "    \n",
    "    div_auctions = soup.find_all('div', class_=\"player-prices-live-auctions\")\n",
    "    \n",
    "    for div in div_auctions:\n",
    "        div.find('div', class_=\"player-prices-live-auctions\")\n",
    "    \n",
    "    auction_table = soup.select_one(\"table:nth-of-type(1)\")\n",
    "    \n",
    "    rows = auction_table.find_all('tr')\n",
    "    num_rows = min ( len(rows), 5 )\n",
    "    #title row\n",
    "    row = rows[0]\n",
    "    td_tags = row.find_all('td')\n",
    "    th_tags = row.find_all('th') \n",
    "\n",
    "    titles = []\n",
    "\n",
    "    for tag in th_tags:\n",
    "        titles.append(str(tag)[4:-5]) #remove tags\n",
    "    \n",
    "    num_cols = len(titles)\n",
    "\n",
    "    new_table = pd.DataFrame(columns=titles, index=range(0,num_rows-1))\n",
    "\n",
    "    for i in range(1,num_rows):\n",
    "        row = rows[i]\n",
    "\n",
    "        td_tags = row.find_all('td')\n",
    "\n",
    "        values = []\n",
    "\n",
    "        for val in td_tags:\n",
    "            values.append(str(val)[4:-5])\n",
    "    \n",
    "        #time remaining\n",
    "        time_rem = values[0][58:67].replace(\"<\", \"\").replace(\">\", \"\")\n",
    "        num_bids = values[1]\n",
    "        curr_bid = values[2]\n",
    "        buy_now = values[3]\n",
    "        nums = [time_rem, num_bids, curr_bid, buy_now]\n",
    "        j=0\n",
    "    \n",
    "        for title in titles:\n",
    "            new_table[title][i-1] = nums[j]\n",
    "            j += 1\n",
    "    \n",
    "    return new_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_stats(soup):  # method to return dataframe of stats for last 100 sales such as quartile prices, min, avg\n",
    "    \n",
    "    div_hist = soup.find_all('div', class_=\"player-details-right\")\n",
    "    \n",
    "    for div in div_hist:\n",
    "        t = div.find('div', class_=\"player-prices-advanced-statistics\")\n",
    "        hist_table = t.select_one(\"table:nth-of-type(1)\")\n",
    "    \n",
    "        rows = hist_table.find_all('tr')\n",
    "\n",
    "    new_table2 = pd.DataFrame(columns=['Q', 'Price'], index=[0,1,2,3,4,5,6])\n",
    "    \n",
    "    for i in range(0,7): #first row of prices\n",
    "        row = rows[i]\n",
    "        td_tags = row.find_all('td')\n",
    "        \n",
    "        values = []\n",
    "\n",
    "        for val in td_tags:\n",
    "            values.append(str(val)[4:-5])\n",
    "    \n",
    "        #time remaining\n",
    "        ca = values[0]\n",
    "        cb = values[1][14:]\n",
    "    \n",
    "        nums = [ca,cb]\n",
    "        #print(nums) # debug\n",
    "        new_table2['Q'][i] = ca\n",
    "        new_table2['Price'][i] = cb\n",
    "    \n",
    "    return new_table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_sales(soup):    # method to return dataframe of last n completed sales ( <= 10?)\n",
    "    \n",
    "    div_sales = soup.find_all('div', class_=\"player-prices-completed-sales\")\n",
    "\n",
    "    sales_table = soup.select_one(\"table:nth-of-type(2)\")\n",
    "    rows = sales_table.find_all('tr')\n",
    "    num_rows = min ( len(rows), 10 )\n",
    "    \n",
    "    row = rows[0] #title row\n",
    "    td_tags = row.find_all('td')\n",
    "    th_tags = row.find_all('th') \n",
    "    \n",
    "    titles = []\n",
    "\n",
    "    for tag in th_tags:\n",
    "        titles.append(str(tag)[4:-5]) #remove tags\n",
    "    \n",
    "    num_cols = len(titles)\n",
    "    new_table3 = pd.DataFrame(columns=titles, index=range(0,num_rows-1))\n",
    "   \n",
    "    for i in range(1,num_rows):\n",
    "        row = rows[i]\n",
    "\n",
    "        td_tags = row.find_all('td')\n",
    "\n",
    "        values = []\n",
    "\n",
    "        for val in td_tags:\n",
    "            values.append(str(val)[4:-5])\n",
    "            \n",
    "        time_sold = values[0][119:140].replace(\"<\", \"\").replace(\">\", \"\")\n",
    "        price_sold = values[1].replace(\".\", \"\").replace(\",\", \"\")\n",
    "        \n",
    "        nums = [time_sold, price_sold] #print(nums) # debug\n",
    "        j=0\n",
    "    \n",
    "        for title in titles:\n",
    "            new_table3[title][i-1] = nums[j]\n",
    "            j += 1\n",
    "            \n",
    "    new_table3['Price'] = pd.to_numeric( new_table3['Price'] )\n",
    "    return new_table3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start here\n",
    "Place players and their respective IDs in parallel arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PLAYERS WE WANT TO SEARCH ARE DIVIDED INTO TWO LISTS OF NAMES AND PLAYERIDS\n",
    "\n",
    "# Set Player Names\n",
    "#player_names = ['Any Dalton', 'Laremy Tunsil', 'Lamer Miller', 'Eric Decker', 'Ben Watson', 'Spencer Long', 'Brian Lafell', 'Don Barclay']\n",
    "player_names = ['Kirk Cousins', 'Jahri Evans', 'Zach Miller', 'Martavis Bryant', 'Russell Okung', 'Brandon Fusco', \\\n",
    "               'Ryan Mathews', 'Dwayne Harris']\n",
    "# Set Player IDs\n",
    "#player_ids = ['34093', '34094', '34095', '34096', '34101', '34102', '34103', '34104']\n",
    "player_ids = ['34165', '34166', '34167', '34168', '34173', '34174', '34175', '34176'  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To refresh prices:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_start = 'https://www.muthead.com/18/players/prices/'\n",
    "link_end = '/playstation-4/'\n",
    "link_end_ref = '/playstation-4/refresh/'\n",
    "start = time.time()\n",
    "print(\"timestart\")\n",
    "\n",
    "for k in range(0, len(player_ids)):\n",
    "    linky = link_start + player_ids[k] + link_end_ref\n",
    "    browser.get(linky)\n",
    "    time.sleep(5)\n",
    "#browser.quit()  # uncomment to close browser but will log you out of site\n",
    "\n",
    "end = time.time()\n",
    "print('Time in seconds for completion:\\t', end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scraping the data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestart\n",
      "\n",
      "= = = = = Current Prices for Kirk Cousins = = = = = \n",
      "retrieving prices\n",
      "Kirk Cousins Prices - Madden 18 - 93 OVR NFL Replays - Muthead \n",
      "retrieving stats\n",
      "\n",
      "Time elapsed:\t 7.441845178604126\n",
      "\n",
      "= = = = = Current Prices for Jahri Evans = = = = = \n",
      "retrieving prices\n",
      "Jahri Evans Prices - Madden 18 - 92 OVR NFL Replays - Muthead \n",
      "retrieving stats\n",
      "\n",
      "Time elapsed:\t 15.211973905563354\n",
      "\n",
      "= = = = = Current Prices for Zach Miller = = = = = \n",
      "retrieving prices\n",
      "Zach Miller Prices - Madden 18 - 91 OVR NFL Replays - Muthead \n",
      "retrieving stats\n",
      "\n",
      "======DEAL======\n",
      "Time elapsed:\t 22.66271710395813\n",
      "\n",
      "= = = = = Current Prices for Martavis Bryant = = = = = \n",
      "retrieving prices\n",
      "Martavis Bryant Prices - Madden 18 - 91 OVR NFL Replays - Muthead \n",
      "retrieving stats\n",
      "\n",
      "Time elapsed:\t 30.36227011680603\n",
      "\n",
      "= = = = = Current Prices for Russell Okung = = = = = \n",
      "retrieving prices\n",
      "Russell Okung Prices - Madden 18 - 89 OVR NFL Replays - Muthead \n",
      "retrieving stats\n",
      "\n",
      "Time elapsed:\t 38.11774015426636\n",
      "\n",
      "= = = = = Current Prices for Brandon Fusco = = = = = \n",
      "retrieving prices\n",
      "Brandon Fusco Prices - Madden 18 - 88 OVR NFL Replays - Muthead \n",
      "retrieving stats\n",
      "\n",
      "Time elapsed:\t 45.81132125854492\n",
      "\n",
      "= = = = = Current Prices for Ryan Mathews = = = = = \n",
      "retrieving prices\n",
      "Ryan Mathews Prices - Madden 18 - 87 OVR NFL Replays - Muthead \n",
      "retrieving stats\n",
      "\n",
      "======DEAL======\n",
      "Time elapsed:\t 53.495814085006714\n",
      "\n",
      "= = = = = Current Prices for Dwayne Harris = = = = = \n",
      "retrieving prices\n",
      "Dwayne Harris Prices - Madden 18 - 86 OVR NFL Replays - Muthead \n",
      "retrieving stats\n",
      "\n",
      "Time elapsed:\t 61.28332495689392\n",
      "Time in seconds for completion:\t 61.28368306159973\n"
     ]
    }
   ],
   "source": [
    "start = time.time() # INITIALIZE TIMER FOR COMPUTING TIME\n",
    "print(\"timestart\")\n",
    "\n",
    "link_start = 'https://www.muthead.com/18/players/prices/' # LINK PREFIX/POSTFIX\n",
    "link_end = '/playstation-4/'\n",
    "\n",
    "min_prices = [] # LIST FOR LOWEST BUYITNOW PRICE PER PLAYER\n",
    "N = len(player_names)\n",
    "\n",
    "for i in range(0,N):\n",
    "    mut_url = link_start + player_ids[i] + link_end\n",
    "    r = urllib.request.urlopen(mut_url).read()\n",
    "    soup = BeautifulSoup(r,\"lxml\")\n",
    "    time.sleep(2) \n",
    "    print('\\n= = = = = Current Prices for', player_names[i], '= = = = = ')\n",
    "    print('retrieving prices')\n",
    "    df = retrieve_prices(soup)\n",
    "    time.sleep(2) \n",
    "    print('retrieving stats')\n",
    "    df2 = retrieve_stats(soup)\n",
    "    time.sleep(2)\n",
    "    print()\n",
    "    \n",
    "    current_min = df['Buy Now Price'][0].replace(\",\", \"\")\n",
    "    lower_q = df2['Price'][5].replace(\",\", \"\")\n",
    "    \n",
    "    # potential deal\n",
    "    if ( float(current_min) < float(lower_q) ):\n",
    "        print ('======DEAL======')\n",
    "        \n",
    "    min_prices.append(current_min)\n",
    "    \n",
    "    temp = time.time()\n",
    "    print('Time elapsed:\\t', temp - start)\n",
    "    \n",
    "end = time.time()\n",
    "print('Time in seconds for completion:\\t', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['135000', '86500', '84500', '64000', '17750', '29000', '7900', '18000']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate the price we can get for the player obtained by completing the set and determine whether it is a worthwhile venture:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost to Build:\t 442650\n",
      "retrieving prices\n",
      "Dez Bryant Prices - Madden 18 - 97 OVR NFL Replays - Muthead \n",
      "retrieving stats\n",
      "\n",
      "X X X X X X NOT WORTH IT! X X X X X X\n",
      "\n",
      "Kirk Cousins\t135000\n",
      "Jahri Evans\t86500\n",
      "Zach Miller\t84500\n",
      "Martavis Bryant\t64000\n",
      "Russell Okung\t17750\n",
      "Brandon Fusco\t29000\n",
      "Ryan Mathews\t7900\n",
      "Dwayne Harris\t18000\n",
      "\n",
      "Cost to build:\t\t 442650\n",
      "Lowest Dez Bryant:\t 459000\n",
      "After Tax :\t\t 413100\n",
      "Last x mean:\t\t 482166\n",
      "Potential profit:\t -29550\n",
      "\n",
      "Time in seconds for completion:\t 9.86\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "summ = 0\n",
    "for i in range(0,8):\n",
    "    summ+= int(min_prices[i])\n",
    "    \n",
    "print('Cost to Build:\\t', summ)\n",
    "\n",
    "#target = 'Trent Williams'\n",
    "#target_id = '34091'\n",
    "target = 'Dez Bryant'\n",
    "target_id = '34163'\n",
    "\n",
    "mut_url = link_start + target_id + link_end\n",
    "r = urllib.request.urlopen(mut_url).read()\n",
    "soup = BeautifulSoup(r,\"lxml\")\n",
    "time.sleep(5) \n",
    "print('retrieving prices')\n",
    "df = retrieve_prices(soup)\n",
    "time.sleep(3) \n",
    "print('retrieving stats')\n",
    "df2 = retrieve_stats(soup)\n",
    "print()\n",
    "df3 = retrieve_sales(soup)\n",
    "\n",
    "current_min = df['Buy Now Price'][0].replace(\",\", \"\")\n",
    "lower_q = df2['Price'][5].replace(\",\", \"\")\n",
    "last_x_mean = df3['Price'].mean()\n",
    "       \n",
    "cur_min = float (current_min )\n",
    "after_tax = cur_min*0.9\n",
    "\n",
    "if ( after_tax > summ):\n",
    "    print('==+++===== BUY! BUY! BUY! =====+++==\\n')\n",
    "else:\n",
    "    print('X X X X X X NOT WORTH IT! X X X X X X\\n')\n",
    "    \n",
    "for i in range(0, 8):\n",
    "    print( player_names[i] + '\\t' + min_prices[i] )\n",
    "\n",
    "print ('\\nCost to build:\\t\\t', summ)\n",
    "print ('Lowest ' + target +':\\t', int(cur_min))\n",
    "print ('After Tax :\\t\\t', int(after_tax))\n",
    "print ('Last x mean:\\t\\t', int(last_x_mean) )\n",
    "print('Potential profit:\\t', int(after_tax-summ))\n",
    "\n",
    "end = time.time()\n",
    "timey = end - start\n",
    "timey = str(round(timey, 2))\n",
    "\n",
    "print('\\nTime in seconds for completion:\\t', timey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Matthew Johnson, March 21, 2018"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
