{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Madden Ultimate Team (MUT) Auction House Analyzer\n",
    "\n",
    "A set in madden is where you buy n specific cards to complete the set and recieve a more valuable player in return.\n",
    "Given an input of set players, ids, and the reward allows you to find arbitrage in the MUT Auction House.\n",
    "\n",
    "Currently:\n",
    "- Currently running two parallel arrays of set players and their ids\n",
    "- Keep track of target player and target_id \n",
    "- Use selenium to open webdriver Firefox\n",
    "- Manually log into 'Muthead' (Must be logged in to refresh auction prices)\n",
    "- Selenium refreshes all of the auction prices of relevant players page by page\n",
    "- Use beautifulsoup to scrape from three tables: Current Auctions, Completed Sales, and 'Stats for Nerds'\n",
    "- Using the minimum BuyNow price for each player, the price to complete the set is calculated\n",
    "- Using this, an average of last n sales of player and taking into account the 10% tax fee on the Auction House a conditional is triggered to pursue the set based on expected profit\n",
    "\n",
    "Current Pitfalls:\n",
    "- Need to manually login\n",
    "- Poor flow\n",
    "- Likely needs proper use of .sleep() \n",
    "\n",
    "Planned:\n",
    "- store data, pickle?\n",
    "- to also use for non-set (rare) players\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RUN THIS\n",
    "\n",
    "browser = webdriver.Firefox()\n",
    "\n",
    "URL = 'https://www.muthead.com/twitch-login?returnUrl=%2f'\n",
    "\n",
    "browser.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#manually log in\n",
    "\n",
    "# data frame to store scraped data\n",
    "data = pd.DataFrame(columns=['Name', 'Min Price', 'Average', 'Date'], index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_prices(soup):    # method that returns a dataframe of current auctions\n",
    "    \n",
    "    print (soup.title.text) # print player page title\n",
    "    \n",
    "    div_auctions = soup.find_all('div', class_=\"player-prices-live-auctions\")\n",
    "    \n",
    "    for div in div_auctions:\n",
    "        div.find('div', class_=\"player-prices-live-auctions\")\n",
    "    \n",
    "    auction_table = soup.select_one(\"table:nth-of-type(1)\")\n",
    "    \n",
    "    rows = auction_table.find_all('tr')\n",
    "    num_rows = min ( len(rows), 5 )\n",
    "    #title row\n",
    "    row = rows[0]\n",
    "    td_tags = row.find_all('td')\n",
    "    th_tags = row.find_all('th') \n",
    "\n",
    "    titles = []\n",
    "\n",
    "    for tag in th_tags:\n",
    "        titles.append(str(tag)[4:-5]) #remove tags\n",
    "    \n",
    "    num_cols = len(titles)\n",
    "\n",
    "    new_table = pd.DataFrame(columns=titles, index=range(0,num_rows-1))\n",
    "\n",
    "    for i in range(1,num_rows):\n",
    "        row = rows[i]\n",
    "\n",
    "        td_tags = row.find_all('td')\n",
    "\n",
    "        values = []\n",
    "\n",
    "        for val in td_tags:\n",
    "            values.append(str(val)[4:-5])\n",
    "    \n",
    "        #time remaining\n",
    "        time_rem = values[0][58:67].replace(\"<\", \"\").replace(\">\", \"\")\n",
    "        num_bids = values[1]\n",
    "        curr_bid = values[2]\n",
    "        buy_now = values[3]\n",
    "        nums = [time_rem, num_bids, curr_bid, buy_now]\n",
    "        #print(nums) # debug\n",
    "        j=0\n",
    "    \n",
    "        for title in titles:\n",
    "            new_table[title][i-1] = nums[j]\n",
    "            j += 1\n",
    "    \n",
    "    return new_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_stats(soup):  # method to return dataframe of stats for last 100 sales such as quartile prices, min, avg\n",
    "    \n",
    "    div_hist = soup.find_all('div', class_=\"player-details-right\")\n",
    "    \n",
    "    for div in div_hist:\n",
    "        t = div.find('div', class_=\"player-prices-advanced-statistics\")\n",
    "        hist_table = t.select_one(\"table:nth-of-type(1)\")\n",
    "    \n",
    "        rows = hist_table.find_all('tr')\n",
    "\n",
    "    new_table2 = pd.DataFrame(columns=['Q', 'Price'], index=[0,1,2,3,4,5,6])\n",
    "    \n",
    "    for i in range(0,7): #first row of prices\n",
    "        row = rows[i]\n",
    "        td_tags = row.find_all('td')\n",
    "        \n",
    "        values = []\n",
    "\n",
    "        for val in td_tags:\n",
    "            values.append(str(val)[4:-5])\n",
    "    \n",
    "        #time remaining\n",
    "        ca = values[0]\n",
    "        cb = values[1][14:]\n",
    "    \n",
    "        nums = [ca,cb]\n",
    "        #print(nums) # debug\n",
    "        new_table2['Q'][i] = ca\n",
    "        new_table2['Price'][i] = cb\n",
    "    \n",
    "    return new_table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_sales(soup):    # method to return dataframe of last n completed sales ( <= 10?)\n",
    "    \n",
    "    div_sales = soup.find_all('div', class_=\"player-prices-completed-sales\")\n",
    "\n",
    "    sales_table = soup.select_one(\"table:nth-of-type(2)\")\n",
    "    rows = sales_table.find_all('tr')\n",
    "    num_rows = min ( len(rows), 10 )\n",
    "    \n",
    "    row = rows[0] #title row\n",
    "    td_tags = row.find_all('td')\n",
    "    th_tags = row.find_all('th') \n",
    "    \n",
    "    titles = []\n",
    "\n",
    "    for tag in th_tags:\n",
    "        titles.append(str(tag)[4:-5]) #remove tags\n",
    "    \n",
    "    num_cols = len(titles)\n",
    "    new_table3 = pd.DataFrame(columns=titles, index=range(0,num_rows-1))\n",
    "   \n",
    "    for i in range(1,num_rows):\n",
    "        row = rows[i]\n",
    "\n",
    "        td_tags = row.find_all('td')\n",
    "\n",
    "        values = []\n",
    "\n",
    "        for val in td_tags:\n",
    "            values.append(str(val)[4:-5])\n",
    "            \n",
    "        time_sold = values[0][119:140].replace(\"<\", \"\").replace(\">\", \"\")\n",
    "        price_sold = values[1].replace(\".\", \"\").replace(\",\", \"\")\n",
    "        \n",
    "        nums = [time_sold, price_sold] #print(nums) # debug\n",
    "        j=0\n",
    "    \n",
    "        for title in titles:\n",
    "            new_table3[title][i-1] = nums[j]\n",
    "            j += 1\n",
    "            \n",
    "    new_table3['Price'] = pd.to_numeric( new_table3['Price'] )\n",
    "    return new_table3\n",
    "\n",
    "#new_table3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set Player Names\n",
    "player_names = ['Any Dalton', 'Laremy Tunsil', 'Lamer Miller', 'Eric Decker', 'Ben Watson', 'Spencer Long', 'Brian Lafell', 'Don Barclay']\n",
    "# Set Player IDs\n",
    "player_ids = ['34093', '34094', '34095', '34096', '34101', '34102', '34103', '34104']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "link_start = 'https://www.muthead.com/18/players/prices/'\n",
    "link_end = '/playstation-4/'\n",
    "link_end_ref = '/playstation-4/refresh/'\n",
    "start = time.time()\n",
    "print(\"timestart\")\n",
    "\n",
    "for k in range(0, len(player_ids)):\n",
    "    linky = link_start + player_ids[k] + link_end_ref\n",
    "    browser.get(linky)\n",
    "    time.sleep(5)\n",
    "#browser.quit()  # uncomment to close browser but will log you out of site\n",
    "\n",
    "end = time.time()\n",
    "print('Time in seconds for completion:\\t', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestart\n",
      "\n",
      "= = = = = Current Prices for Any Dalton = = = = = \n",
      "retrieving prices\n",
      "Andy Dalton Prices - Madden 18 - 93 OVR NFL Replays - Muthead \n",
      "retrieving stats\n",
      "\n",
      "Time elapsed:\t 6.4389808177948\n",
      "\n",
      "= = = = = Current Prices for Laremy Tunsil = = = = = \n",
      "retrieving prices\n",
      "Laremy Tunsil Prices - Madden 18 - 92 OVR NFL Replays - Muthead \n",
      "retrieving stats\n",
      "\n",
      "======DEAL======\n",
      "Time elapsed:\t 13.035347938537598\n",
      "\n",
      "= = = = = Current Prices for Lamer Miller = = = = = \n",
      "retrieving prices\n",
      "Lamar Miller Prices - Madden 18 - 91 OVR NFL Replays - Muthead \n",
      "retrieving stats\n",
      "\n",
      "Time elapsed:\t 19.55638289451599\n",
      "\n",
      "= = = = = Current Prices for Eric Decker = = = = = \n",
      "retrieving prices\n",
      "Eric Decker Prices - Madden 18 - 91 OVR NFL Replays - Muthead \n",
      "retrieving stats\n",
      "\n",
      "Time elapsed:\t 26.07814598083496\n",
      "\n",
      "= = = = = Current Prices for Ben Watson = = = = = \n",
      "retrieving prices\n",
      "Benjamin Watson Prices - Madden 18 - 89 OVR NFL Replays - Muthead \n",
      "retrieving stats\n",
      "\n",
      "Time elapsed:\t 32.52758193016052\n",
      "\n",
      "= = = = = Current Prices for Spencer Long = = = = = \n",
      "retrieving prices\n",
      "Spencer Long Prices - Madden 18 - 88 OVR NFL Replays - Muthead \n",
      "retrieving stats\n",
      "\n",
      "Time elapsed:\t 39.02691078186035\n",
      "\n",
      "= = = = = Current Prices for Brian Lafell = = = = = \n",
      "retrieving prices\n",
      "Brandon LaFell Prices - Madden 18 - 87 OVR NFL Replays - Muthead \n",
      "retrieving stats\n",
      "\n",
      "Time elapsed:\t 45.56929683685303\n",
      "\n",
      "= = = = = Current Prices for Don Barclay = = = = = \n",
      "retrieving prices\n",
      "Don Barclay Prices - Madden 18 - 86 OVR NFL Replays - Muthead \n",
      "retrieving stats\n",
      "\n",
      "Time elapsed:\t 52.05195689201355\n",
      "Time in seconds for completion:\t 52.052605867385864\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "start = time.time() # INITIALIZE TIMER FOR COMPUTING TIME\n",
    "print(\"timestart\")\n",
    "\n",
    "link_start = 'https://www.muthead.com/18/players/prices/' # LINK PREFIX/POSTFIX\n",
    "link_end = '/playstation-4/'\n",
    "\n",
    "# PLAYERS WE WANT TO SEARCH ARE DIVIDED INTO TWO LISTS OF NAMES AND PLAYERIDS\n",
    "player_names = ['Any Dalton', 'Laremy Tunsil', 'Lamer Miller', 'Eric Decker', 'Ben Watson', 'Spencer Long', 'Brian Lafell', 'Don Barclay']\n",
    "player_ids = ['34093', '34094', '34095', '34096', '34101', '34102', '34103', '34104']\n",
    "\n",
    "min_prices = [] # LIST FOR LOWEST BUYITNOW PRICE PER PLAYER\n",
    "N = len(player_names)\n",
    "\n",
    "for i in range(0,N):\n",
    "    mut_url = link_start + player_ids[i] + link_end\n",
    "    r = urllib.request.urlopen(mut_url).read()\n",
    "    soup = BeautifulSoup(r,\"lxml\")\n",
    "    time.sleep(2) \n",
    "    print('\\n= = = = = Current Prices for', player_names[i], '= = = = = ')\n",
    "    print('retrieving prices')\n",
    "    df = retrieve_prices(soup)\n",
    "    time.sleep(2) \n",
    "    print('retrieving stats')\n",
    "    df2 = retrieve_stats(soup)\n",
    "    time.sleep(2)\n",
    "    print()\n",
    "    \n",
    "    current_min = df['Buy Now Price'][0].replace(\",\", \"\")\n",
    "    lower_q = df2['Price'][5].replace(\",\", \"\")\n",
    "    #avg = df2['Price'][0].replace(\",\", \"\")\n",
    "    \n",
    "    # potential deal\n",
    "    if ( float(current_min) < float(lower_q) ):\n",
    "        print ('======DEAL======')\n",
    "        \n",
    "    #print ('Current Min:\\t', current_min)\n",
    "    #print ('Avg Price:\\t', avg)\n",
    "    #print ('Q1 Price:\\t', lower_q)\n",
    "    min_prices.append(current_min)\n",
    "    #summy += int(current_min)\n",
    "    \n",
    "    temp = time.time()\n",
    "    print('Time elapsed:\\t', temp - start)\n",
    "    \n",
    "    \n",
    "end = time.time()\n",
    "print('Time in seconds for completion:\\t', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['101000', '70000', '70500', '53000', '17500', '29000', '12000', '9900']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost to Build:\t 362900\n",
      "retrieving prices\n",
      "Trent Williams Prices - Madden 18 - 97 OVR NFL Replays - Muthead \n",
      "retrieving stats\n",
      "\n",
      "==+++===== BUY! BUY! BUY! =====+++==\n",
      "\n",
      "Any Dalton\t101000\n",
      "Laremy Tunsil\t70000\n",
      "Lamer Miller\t70500\n",
      "Eric Decker\t53000\n",
      "Ben Watson\t17500\n",
      "Spencer Long\t29000\n",
      "Brian Lafell\t12000\n",
      "Don Barclay\t9900\n",
      "\n",
      "Cost to build:\t\t 362900\n",
      "Lowest Trent Williams:\t 415000\n",
      "After Tax :\t\t 373500\n",
      "Last x mean:\t\t 407222\n",
      "Potential profit:\t 10600\n",
      "\n",
      "Time in seconds for completion:\t 8.52\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "summ = 0\n",
    "for i in range(0,8):\n",
    "    summ+= int(min_prices[i])\n",
    "    \n",
    "print('Cost to Build:\\t', summ)\n",
    "\n",
    "target = 'Trent Williams'\n",
    "target_id = '34091'\n",
    "\n",
    "mut_url = link_start + target_id + link_end\n",
    "r = urllib.request.urlopen(mut_url).read()\n",
    "soup = BeautifulSoup(r,\"lxml\")\n",
    "time.sleep(5) \n",
    "print('retrieving prices')\n",
    "df = retrieve_prices(soup)\n",
    "time.sleep(3) \n",
    "print('retrieving stats')\n",
    "df2 = retrieve_stats(soup)\n",
    "print()\n",
    "df3 = retrieve_sales(soup)\n",
    "\n",
    "current_min = df['Buy Now Price'][0].replace(\",\", \"\")\n",
    "lower_q = df2['Price'][5].replace(\",\", \"\")\n",
    "last_x_mean = df3['Price'].mean()\n",
    "       \n",
    "cur_min = float (current_min )\n",
    "after_tax = cur_min*0.9\n",
    "\n",
    "if ( after_tax > summ):\n",
    "    print('==+++===== BUY! BUY! BUY! =====+++==\\n')\n",
    "else:\n",
    "    print('X X X X X X NOT WORTH IT! X X X X X X\\n')\n",
    "    \n",
    "for i in range(0, 8):\n",
    "    print( player_names[i] + '\\t' + min_prices[i] )\n",
    "\n",
    "print ('\\nCost to build:\\t\\t', summ)\n",
    "print ('Lowest ' + target +':\\t', int(cur_min))\n",
    "print ('After Tax :\\t\\t', int(after_tax))\n",
    "print ('Last x mean:\\t\\t', int(last_x_mean) )\n",
    "print('Potential profit:\\t', int(after_tax-summ))\n",
    "\n",
    "end = time.time()\n",
    "timey = end - start\n",
    "timey = str(round(timey, 2))\n",
    "\n",
    "print('\\nTime in seconds for completion:\\t', timey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time Remaining</th>\n",
       "      <th># of Bids</th>\n",
       "      <th>Current Bid</th>\n",
       "      <th>Buy Now Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05:58:27</td>\n",
       "      <td>0</td>\n",
       "      <td>414,000</td>\n",
       "      <td>415,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01:42:31</td>\n",
       "      <td>0</td>\n",
       "      <td>409,000</td>\n",
       "      <td>416,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09:59:39</td>\n",
       "      <td>0</td>\n",
       "      <td>399,000</td>\n",
       "      <td>419,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04:07:15</td>\n",
       "      <td>0</td>\n",
       "      <td>395,000</td>\n",
       "      <td>420,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Time Remaining # of Bids Current Bid Buy Now Price\n",
       "0       05:58:27         0     414,000       415,000\n",
       "1       01:42:31         0     409,000       416,000\n",
       "2       09:59:39         0     399,000       419,000\n",
       "3       04:07:15         0     395,000       420,000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# todo: code to save into dataframe (long term)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Matthew Johnson, March 21, 2018"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
