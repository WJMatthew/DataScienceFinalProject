{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Madden Ultimate Team (MUT) Auction House Analyzer\n",
    "\n",
    "A set in madden is where you buy n specific cards to complete the set and recieve a more valuable player in return.\n",
    "Given an input of set players, ids, and the reward allows you to find arbitrage in the MUT Auction House.\n",
    "\n",
    "Currently:\n",
    "- Currently running two parallel arrays of set players and their ids\n",
    "- Keep track of target player and target_id \n",
    "- Use selenium to open webdriver Firefox\n",
    "- Manually log into 'Muthead' (Must be logged in to refresh auction prices)\n",
    "- Selenium refreshes all of the auction prices of relevant players page by page\n",
    "- Use beautifulsoup to scrape from three tables: Current Auctions, Completed Sales, and 'Stats for Nerds'\n",
    "- Using the minimum BuyNow price for each player, the price to complete the set is calculated\n",
    "- Using this, an average of last n sales of player and taking into account the 10% tax fee on the Auction House a conditional is triggered to pursue the set based on expected profit\n",
    "\n",
    "Current Pitfalls:\n",
    "- Need to manually login\n",
    "- Poor flow\n",
    "- Likely needs proper use of .sleep() \n",
    "\n",
    "Planned:\n",
    "- store data, pickle?\n",
    "- to also use for non-set (rare) players\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_prices(auction_table):    # method that returns a dataframe of current auctions\n",
    "    \n",
    "    print (soup.title.text) # print player page title\n",
    "    \n",
    "    rows = auction_table.find_all('tr')\n",
    "    num_rows = min ( len(rows), 5 )\n",
    "    #title row\n",
    "    row = rows[0]\n",
    "    td_tags = row.find_all('td')\n",
    "    th_tags = row.find_all('th') \n",
    "\n",
    "    titles = []\n",
    "\n",
    "    for tag in th_tags:\n",
    "        titles.append(str(tag)[4:-5]) #remove tags\n",
    "    \n",
    "    num_cols = len(titles)\n",
    "\n",
    "    new_table = pd.DataFrame(columns=titles, index=range(0,num_rows-1))\n",
    "\n",
    "    for i in range(1,num_rows):\n",
    "        row = rows[i]\n",
    "\n",
    "        td_tags = row.find_all('td')\n",
    "\n",
    "        values = []\n",
    "\n",
    "        for val in td_tags:\n",
    "            values.append(str(val)[4:-5])\n",
    "    \n",
    "        #time remaining\n",
    "        time_rem = values[0][58:67].replace(\"<\", \"\").replace(\">\", \"\")\n",
    "        num_bids = values[1]\n",
    "        curr_bid = values[2]\n",
    "        buy_now = values[3]\n",
    "        nums = [time_rem, num_bids, curr_bid, buy_now]\n",
    "        j=0\n",
    "    \n",
    "        for title in titles:\n",
    "            new_table[title][i-1] = nums[j]\n",
    "            j += 1\n",
    "    \n",
    "    return new_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_stats(hist_table):  # method to return dataframe of stats for last 100 sales such as quartile prices, min, avg\n",
    "    \n",
    "    rows = hist_table.find_all('tr')\n",
    "\n",
    "    new_table2 = pd.DataFrame(columns=['Q', 'Price'], index=[0,1,2,3,4,5,6])\n",
    "    \n",
    "    for i in range(0,7): #first row of prices\n",
    "        row = rows[i]\n",
    "        td_tags = row.find_all('td')\n",
    "        \n",
    "        values = []\n",
    "\n",
    "        for val in td_tags:\n",
    "            values.append(str(val))\n",
    " \n",
    "        #time remaining\n",
    "        ca = values[0]\n",
    "        cb = values[1]\n",
    "    \n",
    "        nums = [ca,cb]\n",
    "        new_table2['Q'][i] = ca\n",
    "        new_table2['Price'][i] = cb\n",
    "    \n",
    "    return new_table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_sales(sales_table):    # method to return dataframe of last n completed sales ( <= 10?)\n",
    "    \n",
    "    rows = sales_table.find_all('tr')\n",
    "    num_rows = min ( len(rows), 10 )\n",
    "    \n",
    "    row = rows[0] #title row\n",
    "    td_tags = row.find_all('td')\n",
    "    th_tags = row.find_all('th') \n",
    "    \n",
    "    titles = []\n",
    "\n",
    "    for tag in th_tags:\n",
    "        titles.append(str(tag)[4:-5]) #remove tags\n",
    "    \n",
    "    num_cols = len(titles)\n",
    "    new_table3 = pd.DataFrame(columns=titles, index=range(0,num_rows-1))\n",
    "   \n",
    "    for i in range(1,num_rows):\n",
    "        row = rows[i]\n",
    "\n",
    "        td_tags = row.find_all('td')\n",
    "\n",
    "        values = []\n",
    "\n",
    "        for val in td_tags:\n",
    "            values.append(str(val)[4:-5])\n",
    "            \n",
    "        time_sold = values[0][119:140].replace(\"<\", \"\").replace(\">\", \"\")\n",
    "        price_sold = values[1].replace(\".\", \"\").replace(\",\", \"\")\n",
    "        \n",
    "        nums = [time_sold, price_sold] #print(nums) # debug\n",
    "        j=0\n",
    "    \n",
    "        for title in titles:\n",
    "            new_table3[title][i-1] = nums[j]\n",
    "            j += 1\n",
    "            \n",
    "    new_table3['Price'] = pd.to_numeric( new_table3['Price'] )\n",
    "    return new_table3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## price refresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RUN THIS\n",
    "\n",
    "browser = webdriver.Firefox()\n",
    "\n",
    "URL = 'https://www.muthead.com/twitch-login?returnUrl=%2f'\n",
    "\n",
    "browser.get(URL)\n",
    "\n",
    "#manually log in\n",
    "\n",
    "# data frame to store scraped data\n",
    "data = pd.DataFrame(columns=['Name', 'Min Price', 'Average', 'Date'], index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set Player Names\n",
    "player_names = ['Any Dalton', 'Laremy Tunsil', 'Lamer Miller', 'Eric Decker', 'Ben Watson', 'Spencer Long', 'Brian Lafell', 'Don Barclay']\n",
    "\n",
    "# Set Player IDs\n",
    "player_ids = ['34093', '34094', '34095', '34096', '34101', '34102', '34103', '34104']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use only when necessary, refreshes all player data from site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestart\n",
      "Time in seconds for completion:\t 22.184700965881348\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "link_start = 'https://www.muthead.com/18/players/prices/'\n",
    "link_end = '/playstation-4/'\n",
    "link_end_ref = '/playstation-4/refresh/'\n",
    "start = time.time()\n",
    "print(\"timestart\")\n",
    "\n",
    "for k in range(0, len(player_ids)):\n",
    "    linky = link_start + player_ids[k] + link_end_ref\n",
    "    browser.get(linky)\n",
    "    time.sleep(1)\n",
    "    #browser.quit()  # uncomment to close browser but will log you out of site\n",
    "\n",
    "end = time.time()\n",
    "print('Time in seconds for completion:\\t', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestart\n",
      "\n",
      "= = = = =  Any Dalton = = = = = \n",
      "retrieving prices\n",
      "Andy Dalton Prices - Madden 18 - 93 OVR NFL Replays - Muthead \n",
      "retrieving stats\n",
      "\n",
      "Time elapsed:\t 2.5251030921936035\n",
      "\n",
      "= = = = =  Laremy Tunsil = = = = = \n",
      "retrieving prices\n",
      "Laremy Tunsil Prices - Madden 18 - 92 OVR NFL Replays - Muthead \n",
      "retrieving stats\n",
      "\n",
      "Time elapsed:\t 5.018953084945679\n",
      "\n",
      "= = = = =  Lamer Miller = = = = = \n",
      "retrieving prices\n",
      "Lamar Miller Prices - Madden 18 - 91 OVR NFL Replays - Muthead \n",
      "retrieving stats\n",
      "\n",
      "Time elapsed:\t 7.493355989456177\n",
      "\n",
      "= = = = =  Eric Decker = = = = = \n",
      "retrieving prices\n",
      "Eric Decker Prices - Madden 18 - 91 OVR NFL Replays - Muthead \n",
      "retrieving stats\n",
      "\n",
      "Time elapsed:\t 9.992258071899414\n",
      "\n",
      "= = = = =  Ben Watson = = = = = \n",
      "retrieving prices\n",
      "Benjamin Watson Prices - Madden 18 - 89 OVR NFL Replays - Muthead \n",
      "retrieving stats\n",
      "\n",
      "Time elapsed:\t 12.717534065246582\n",
      "\n",
      "= = = = =  Spencer Long = = = = = \n",
      "retrieving prices\n",
      "Spencer Long Prices - Madden 18 - 88 OVR NFL Replays - Muthead \n",
      "retrieving stats\n",
      "\n",
      "Time elapsed:\t 15.158654928207397\n",
      "\n",
      "= = = = =  Brian Lafell = = = = = \n",
      "retrieving prices\n",
      "Brandon LaFell Prices - Madden 18 - 87 OVR NFL Replays - Muthead \n",
      "retrieving stats\n",
      "\n",
      "Time elapsed:\t 17.652743101119995\n",
      "\n",
      "= = = = =  Don Barclay = = = = = \n",
      "retrieving prices\n",
      "Don Barclay Prices - Madden 18 - 86 OVR NFL Replays - Muthead \n",
      "retrieving stats\n",
      "\n",
      "Time elapsed:\t 20.149533987045288\n",
      "Time in seconds for completion:\t 20.150598287582397\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "start = time.time() # INITIALIZE TIMER FOR COMPUTING TIME\n",
    "print(\"timestart\")\n",
    "\n",
    "link_start = 'https://www.muthead.com/18/players/prices/' # LINK PREFIX/POSTFIX\n",
    "link_end = '/playstation-4/'\n",
    "\n",
    "# PLAYERS WE WANT TO SEARCH ARE DIVIDED INTO TWO LISTS OF NAMES AND PLAYERIDS\n",
    "player_names = ['Andy Dalton', 'Laremy Tunsil', 'Lamer Miller', 'Eric Decker', 'Ben Watson', 'Spencer Long', 'Brian Lafell', 'Don Barclay']\n",
    "player_ids = ['34093', '34094', '34095', '34096', '34101', '34102', '34103', '34104']\n",
    "\n",
    "min_prices = [] # LIST FOR LOWEST BUYITNOW PRICE PER PLAYER\n",
    "N = len(player_names)\n",
    "\n",
    "for i in range(0,N):\n",
    "    mut_url = link_start + player_ids[i] + link_end\n",
    "    r = urllib.request.urlopen(mut_url).read()\n",
    "    \n",
    "    soup = BeautifulSoup(r, 'lxml')\n",
    "    \n",
    "    tables = soup.select('table')\n",
    "    \n",
    "    print('\\n= = = = = ', player_names[i], '= = = = = ')\n",
    "    \n",
    "    print('retrieving prices')\n",
    "    df = retrieve_prices(tables[0])\n",
    "    time.sleep(1) \n",
    "    \n",
    "    print('retrieving stats')\n",
    "    df2 = retrieve_stats(tables[2])\n",
    "    time.sleep(1)\n",
    "    \n",
    "    print()\n",
    "    current_min = df['Buy Now Price'][0].replace(\",\", \"\")\n",
    "    lower_q = df2['Price'][5].replace(\",\", \"\")\n",
    "    \n",
    "    # potential deal\n",
    "    \n",
    "    #if ( int(current_min) < int(lower_q) ):     # add back , curr out from string . to float err\n",
    "       # print ('======DEAL======')\n",
    "        \n",
    "    #print ('Current Min:\\t', current_min)\n",
    "    #print ('Avg Price:\\t', avg)\n",
    "    #print ('Q1 Price:\\t', lower_q)\n",
    "    min_prices.append(current_min)\n",
    "    \n",
    "    temp = time.time()\n",
    "    print('Time elapsed:\\t', temp - start)\n",
    "    \n",
    "    \n",
    "end = time.time()\n",
    "print('Time in seconds for completion:\\t', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['90000', '57500', '56500', '43500', '17000', '20250', '8000', '8200']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost to Build:\t 300950\n",
      "retrieving prices\n",
      "Trent Williams Prices - Madden 18 - 97 OVR NFL Replays - Muthead \n",
      "retrieving stats\n",
      "\n",
      "==+++===== BUY! BUY! BUY! =====+++==\n",
      "\n",
      "Any Dalton\t90000\n",
      "Laremy Tunsil\t57500\n",
      "Lamer Miller\t56500\n",
      "Eric Decker\t43500\n",
      "Ben Watson\t17000\n",
      "Spencer Long\t20250\n",
      "Brian Lafell\t8000\n",
      "Don Barclay\t8200\n",
      "\n",
      "Cost to build:\t\t 300950\n",
      "Lowest Trent Williams:\t 395000\n",
      "After Tax :\t\t 355500\n",
      "Last x mean:\t\t 404777\n",
      "Potential profit:\t 54550\n",
      "\n",
      "Time in seconds for completion:\t 2.53\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "summ = 0\n",
    "for i in range(0,8):\n",
    "    summ+= int(min_prices[i])\n",
    "    \n",
    "print('Cost to Build:\\t', summ)\n",
    "\n",
    "target = 'Trent Williams'\n",
    "target_id = '34091'\n",
    "\n",
    "mut_url = link_start + target_id + link_end\n",
    "r = urllib.request.urlopen(mut_url).read()\n",
    "soup = BeautifulSoup(r,\"lxml\")\n",
    "tables = soup.select('table')\n",
    "time.sleep(1) \n",
    "\n",
    "print('retrieving prices')\n",
    "df = retrieve_prices(tables[0])\n",
    "time.sleep(1) \n",
    "\n",
    "print('retrieving stats')\n",
    "df2 = retrieve_stats(tables[2])\n",
    "print()\n",
    "\n",
    "df3 = retrieve_sales(tables[1])\n",
    "\n",
    "current_min = df['Buy Now Price'][0].replace(\",\", \"\")\n",
    "lower_q = df2['Price'][5].replace(\",\", \"\")\n",
    "last_x_mean = df3['Price'].mean()\n",
    "       \n",
    "cur_min = float (current_min )\n",
    "after_tax = cur_min*0.9\n",
    "\n",
    "if ( after_tax > summ):\n",
    "    print('==+++===== BUY! BUY! BUY! =====+++==\\n')\n",
    "else:\n",
    "    print('X X X X X X NOT WORTH IT! X X X X X X\\n')\n",
    "    \n",
    "for i in range(0, 8):\n",
    "    print( player_names[i] + '\\t' + min_prices[i] )\n",
    "\n",
    "print ('\\nCost to build:\\t\\t', summ)\n",
    "print ('Lowest ' + target +':\\t', int(cur_min))\n",
    "print ('After Tax :\\t\\t', int(after_tax))\n",
    "print ('Last x mean:\\t\\t', int(last_x_mean) )\n",
    "print('Potential profit:\\t', int(after_tax-summ))\n",
    "\n",
    "end = time.time()\n",
    "timey = end - start\n",
    "timey = str(round(timey, 2))\n",
    "\n",
    "print('\\nTime in seconds for completion:\\t', timey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: code to save into dataframe (long term)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "headers = {'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_3) \\\n",
    "    AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36'}\n",
    "\n",
    "## do for each player\n",
    "\n",
    "r = requests.get(url, headers=headers)\n",
    "# make sure that the page exist\n",
    "if r.status_code == 200:\n",
    "    html = r.text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    title = soup.find('h1')\n",
    "    if title is not None:\n",
    "        title_text = title.text.strip()\n",
    "        print(title_text)\n",
    "\n",
    "tables = soup.select('table')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Matthew Johnson, March 21, 2018"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
